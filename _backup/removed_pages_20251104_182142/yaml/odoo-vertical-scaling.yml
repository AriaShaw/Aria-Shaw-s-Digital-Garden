metadata:
  title: 'Optimize Application Performance: Improve Performance by 50%'
  description: Comprehensive performance optimization guide for Application. Proven
    techniques to improve Performance with benchmarks, tuning parameters, and monitoring
    strategies.
  intent_type: practitioner
  page_slug: odoo-vertical-scaling
  draft_metadata:
    created_by: pseo-bulk-generator
    template_id: performance
    generation_mode: template
    confidence_level: high
static_data:
  performance_target: Improve overall system performance
  pricelist_id: '1'
  product_id: '100'
  performance_measurement_intro: 'Application performance measurement focuses on end-user
    experience and system responsiveness. Establish baselines for critical user journeys:
    login time, page load times for common views (list, form, kanban), report generation
    duration, and transaction processing speeds. Use browser developer tools (Chrome
    DevTools, Firefox Profiler) to measure client-side metrics: DOM content loaded
    time, time to interactive, first contentful paint, and JavaScript execution time.
    Implement Real User Monitoring (RUM) with tools like Google Analytics, New Relic
    Browser, or open-source alternatives to track actual user experience across geographic
    locations and device types. Server-side metrics include: HTTP response times by
    endpoint, ORM query counts per request (detect N+1 problems), cache hit rates,
    and session management overhead. Set performance budgets: pages should load in
    <2 seconds on 3G, forms should respond in <500ms.'
  database_optimization_details: 'Database optimization focuses on query efficiency
    and connection management for Odoo workloads. Identify slow queries using Odoo''s
    --log-db-level=debug setting combined with PostgreSQL slow query log. Common optimization
    techniques: (1) Eliminate N+1 queries by using ORM read() with field lists instead
    of browse() loops, prefetch related records with .with_prefetch(), batch database
    operations. (2) Add strategic indexes on foreign keys, state fields, and frequently
    filtered columns. Use partial indexes for state-based queries (active records,
    draft documents). (3) Implement database query result caching using Redis for
    expensive aggregations and reports. Cache TTL: 5 minutes for volatile data, 1
    hour for reference data. (4) Optimize ORM operations: use search_count() instead
    of len(search()), use exists() for existence checks, avoid unnecessary field reads.
    (5) Configure PostgreSQL for Odoo: shared_buffers=4-8GB, effective_cache_size=12-16GB,
    work_mem=50MB, max_connections=200 with connection pooling. Monitor query performance
    weekly and maintain index health with regular REINDEX on heavily updated tables.
    Expected improvement: 30-50% reduction in database load.'
  server_configuration_tuning: 'Application server tuning optimizes Odoo configuration
    for performance and scalability. (1) Odoo Configuration (/etc/odoo/odoo.conf):
    Set db_maxconn=64 (PostgreSQL connections per worker), workers=8 (based on CPU
    cores), limit_memory_hard=2684354560 (2.5GB per worker), limit_time_real=120 (request
    timeout). Enable proxy mode if behind reverse proxy (proxy_mode=True). (2) Session
    Management: Configure session storage in Redis instead of PostgreSQL for better
    performance - SESSION_REDIS=True, session_store_timeout=86400 (24 hours). Implement
    session cleanup cron job to prevent bloat. (3) Asset Management: Enable asset
    bundle caching with proper ETags, configure nginx to serve static assets with
    1-year cache headers, implement CDN for global deployments. Precompile assets
    in production: odoo-bin --load-language=en_US --stop-after-init. (4) Database
    Connection Pooling: Implement PgBouncer between Odoo and PostgreSQL with pool_mode=transaction,
    default_pool_size=25, reserve_pool_size=5. (5) Logging Configuration: Set log_level=warn
    for production (avoid debug/info overhead), implement log rotation with max size
    100MB, retain 30 days of logs. Use syslog for centralized logging. Configure log_db=False
    to avoid logging database queries in production. Expected improvement: 20-35%
    reduction in response times under load.'
  asset_optimization_details: 'Asset optimization reduces page load times through
    compression, caching, and delivery optimization. (1) JavaScript/CSS Minification:
    Enable Odoo asset bundling in production mode, combine multiple JS/CSS files into
    single bundles to reduce HTTP requests. Use Odoo asset management to version bundles
    with hash-based cache busting. (2) Image Optimization: Compress images using ImageMagick/Pillow
    before upload - JPEG quality 85%, PNG with pngquant compression. Implement responsive
    images with multiple resolutions using picture elements. Convert large images
    to WebP format for 25-35% size reduction with browser fallbacks. Lazy load images
    below the fold using lazy loading attribute. (3) Static Asset Caching: Configure
    nginx to serve static assets with aggressive caching headers (Cache-Control: public,
    max-age=31536000) for JS/CSS/images with version hashes. Enable gzip compression
    for text assets (gzip_types application/javascript text/css). Implement Brotli
    compression for even better ratios (brotli_comp_level=6). (4) CDN Integration:
    Deploy static assets to CloudFlare, AWS CloudFront, or Fastly CDN for geographic
    distribution. Configure edge caching with 1-hour TTL for dynamic content, 1-year
    for static. (5) Font Optimization: Self-host web fonts instead of Google Fonts
    API, subset fonts to include only used characters (reduces size by 70-90%), use
    font-display:swap to prevent render blocking. Preload critical fonts in HTML head
    element. Expected improvement: 50-70% reduction in page load time, 40-60% reduction
    in bandwidth usage.'
  module_optimization_details: 'Module optimization focuses on custom code efficiency
    and reducing computational overhead. (1) ORM Optimization: Replace search() +
    browse() loops with read() for bulk operations - reduces database queries by 80-95%.
    Use search_read() when only reading fields. Implement with_prefetch() for related
    records to prevent N+1 queries. Avoid unnecessary field reads by specifying field
    lists in read([''name'', ''state'']). (2) Computed Fields: Use @api.depends()
    decorator correctly to limit recomputation scope, implement store=True for frequently
    accessed computed fields if calculation is expensive, use inverse methods for
    writable computed fields. Cache expensive computations using @tools.ormcache decorator
    with cache invalidation on relevant record changes. (3) Batch Processing: Process
    records in batches of 500-1000 using custom iterators, disable mail notification
    during bulk operations with context flag ({''mail_create_nolog'': True}), commit
    transactions periodically in long-running imports. Use cr.commit() judiciously
    in batch operations. (4) Server Actions: Convert button click actions to scheduled
    actions for heavy processing (report generation, mass updates), implement asynchronous
    processing using queue_job module for user-initiated batch operations. (5) Code
    Profiling: Use cProfile to identify bottlenecks (python -m cProfile -o output.prof
    odoo-bin), analyze with snakeviz for visualization. Use line_profiler for function-level
    profiling. Optimize hot paths identified in profiling - typical gains: 60-80%
    reduction in execution time for critical functions. (6) Remove Debug Code: Disable
    development mode in production, remove unnecessary logging statements, disable
    auto-reload (--dev=reload). Expected improvement: 40-70% reduction in custom module
    execution time.'
  caching_implementation: 'Caching strategy implementation requires multi-layer approach
    for maximum performance gains. (1) Application-Level Caching (Redis): Install
    Redis server, configure Odoo session storage to use Redis instead of PostgreSQL
    database (reduces DB load by 40-60%). Cache expensive method results using @tools.ormcache
    decorator with custom cache keys - example: @tools.ormcache(''product_id'', ''pricelist_id'')
    def get_product_price(). Implement cache invalidation using ormcache_context on
    fields that affect cached values. Set Redis maxmemory-policy=allkeys-lru for automatic
    eviction. (2) Database Query Caching: Cache complex report queries in Redis with
    5-15 minute TTL depending on data volatility. Implement invalidation triggers
    on relevant table updates. Use Redis HSET for structured cache (product prices,
    tax calculations) and GET/SET for simple values. Cache aggregation queries (dashboard
    statistics, KPI metrics) with 1-hour TTL. (3) HTTP Caching: Configure nginx proxy
    caching for semi-static content (public pages, product catalogs) with proxy_cache_valid
    200 5m. Implement cache key based on URL + user authentication state. Set X-Accel-Expires
    header in Odoo controllers for per-response cache control. Use nginx fastcgi_cache
    or proxy_cache with 10GB cache zone. (4) Browser Caching: Set appropriate Cache-Control
    headers - static assets: max-age=31536000 (1 year), API responses: max-age=300
    (5 minutes), dynamic pages: no-cache with ETags for validation. Implement service
    workers for offline-capable progressive web app functionality. (5) Object Caching:
    Enable Python function result caching using functools.lru_cache for pure functions,
    implement model-level caching for reference data (countries, currencies, units
    of measure) that rarely changes. Monitor cache hit rates using Redis INFO stats,
    target >80% hit rate for optimal performance. Expected improvement: 60-80% reduction
    in page load time for cached content, 50% reduction in database load.'
  monitoring_strategy: 'Comprehensive monitoring strategy enables proactive performance
    management and issue detection. (1) System Monitoring: Deploy Prometheus with
    node_exporter for OS metrics collection (CPU, memory, disk, network) with 15-second
    scrape intervals. Configure Grafana dashboards for visualization with alert rules:
    CPU >85% for 5 minutes, memory >90%, disk >80%, filesystem inodes >90%. Set up
    multi-level alerts: warning (Slack notification), critical (PagerDuty incident).
    Monitor system logs using Loki or ELK stack for error pattern detection. (2) Application
    Monitoring: Implement Odoo-specific monitoring using custom Prometheus exporters
    tracking: active user sessions, database query counts per endpoint, ORM operation
    statistics, worker process metrics (memory per worker, request queue depth), cron
    job execution times. Set up APM (Application Performance Monitoring) using New
    Relic, DataDog, or open-source alternatives (Elastic APM) for request tracing
    and error tracking. Alert on: response time >2 seconds for critical endpoints,
    error rate >1%, worker saturation >80%. (3) Database Monitoring: Monitor PostgreSQL
    using pg_stat_statements for query performance tracking, enable auto_explain for
    slow queries (auto_explain.log_min_duration=1000), track connection pool usage
    with PgBouncer stats. Set up pgBadger for weekly performance reports, monitor
    replication lag if using streaming replication. Alert on: slow queries >5 seconds,
    database connections >80% of max_connections, replication lag >10 seconds, disk
    space <20% free. (4) Business Metrics: Track KPIs using custom Odoo scheduled
    actions: orders per hour, failed payment transactions, inventory stock-outs, unprocessed
    emails. Create executive dashboards in Grafana showing business health alongside
    technical metrics. (5) Log Analysis: Centralize logs using Graylog or ELK stack,
    implement structured logging with JSON format for machine parsing. Create alerts
    for specific error patterns, track error frequency trends over time. Implement
    log retention policy: 7 days hot storage, 90 days warm storage, 1 year cold storage
    for compliance. Expected outcome: Detect and resolve 90% of performance issues
    before user impact, reduce mean time to detection (MTTD) from hours to minutes.'
  system_name: Application
  performance_metric: Performance
  improvement_target: 50%
  performance_baseline:
    current_metrics:
    - metric: Response Time
      current: 500ms
      target: 200ms
    - metric: Throughput
      current: 100 req/s
      target: 200 req/s
    - metric: Resource Usage
      current: 80%
      target: 50%
  optimization_areas:
  - area: Database Optimization
    techniques:
    - technique: Query Optimization
      implementation: '# Analyze slow queries

        SELECT query, calls, mean_time

        FROM pg_stat_statements

        ORDER BY mean_time DESC

        LIMIT 10;

        '
      expected_improvement: 30-50%
    - technique: Index Optimization
      implementation: '# Create missing indexes

        CREATE INDEX idx_table_name_column_name

        ON table_name(column_name)

        WHERE condition;

        '
      expected_improvement: 20-40%
    - technique: Connection Pooling
      configuration: '# PostgreSQL connection pool

        max_connections = 200

        shared_buffers = 4GB

        effective_cache_size = 12GB

        '
      expected_improvement: 15-25%
  - area: Application Optimization
    techniques:
    - technique: Code Profiling
      tools:
      - 'Python: cProfile, line_profiler'
      - 'JavaScript: Chrome DevTools'
      - 'Database: EXPLAIN ANALYZE'
    - technique: Caching Strategy
      implementation: '# Redis caching configuration

        CACHE_TYPE = ''redis''

        CACHE_REDIS_HOST = ''localhost''

        CACHE_REDIS_PORT = 6379

        CACHE_DEFAULT_TIMEOUT = 300

        '
    - technique: Asynchronous Processing
      implementation: "# Background job processing\nfrom celery import Celery\napp\
        \ = Celery('tasks', broker='redis://localhost')\n\n@app.task\ndef process_heavy_task(data):\n\
        \    # Move heavy processing to background\n    return process(data)\n"
  - area: Infrastructure Optimization
    techniques:
    - technique: Load Balancing
      configuration: "# NGINX load balancer\nupstream backend {\n    least_conn;\n\
        \    server backend1.example.com weight=5;\n    server backend2.example.com;\n\
        \    server backend3.example.com;\n}\n"
    - technique: CDN Implementation
      providers:
      - CloudFlare
      - AWS CloudFront
      - Fastly
      expected_improvement: 40-60% for static assets
  monitoring_setup:
  - tool: Prometheus + Grafana
    metrics:
    - Application response time
    - Database query performance
    - Resource utilization
    dashboard_config: '{}'
  - tool: Application Performance Monitoring (APM)
    options:
    - New Relic
    - DataDog
    - AppDynamics
    key_features:
    - Real-time performance metrics
    - Error tracking
    - User session monitoring
  performance_testing:
  - test: Load Testing
    tool: Apache JMeter / Locust
    scenario: '# Simulate 100 concurrent users

      locust -f loadtest.py --users 100 --spawn-rate 10

      '
  - test: Stress Testing
    objective: Find breaking point
    methodology: Gradually increase load until failure
  optimization_workflow:
  - phase: 1
    name: Measure Baseline
    duration: 1-2 days
    activities:
    - Set up monitoring
    - Record current metrics
    - Identify bottlenecks
  - phase: 2
    name: Quick Wins
    duration: 2-3 days
    optimizations:
    - Database index optimization
    - Enable caching
    - Fix N+1 queries
  - phase: 3
    name: Deep Optimization
    duration: 1-2 weeks
    optimizations:
    - Code refactoring
    - Architecture improvements
    - Infrastructure scaling
  - phase: 4
    name: Validation
    duration: 2-3 days
    activities:
    - Performance testing
    - Metric comparison
    - Documentation
  expected_results:
    overall_improvement: 50%
    roi_timeline: 6 months
  estimated_effort: 2-3 weeks
  complexity_level: Advanced
ai_generated_content:
  introduction: 'Performance degradation in production Odoo systems occurs gradually
    through accumulated maintenance neglect—PostgreSQL tables that never vacuum deleted
    records, database indexes fragmented by constant updates, log files consuming
    disk space, and cached sessions accumulating in memory. This optimization guide
    implements preventive maintenance routines that preserve system performance through
    growth: automated vacuum schedules calibrated for transaction volume, index rebuild
    procedures, log rotation, and monitoring baselines that alert administrators to
    degradation trends before users report problems. The operational discipline documented
    here prevents the emergency performance remediation projects that disrupt business
    operations.

    '
  main_content: "Optimizing Improve overall system performance in Odoo 18 requires\
    \ systematic bottleneck identification before applying optimizations—premature\
    \ optimization wastes time fixing imaginary problems while real bottlenecks continue\
    \ degrading user experience and operational efficiency.\n\nPerformance problems\
    \ manifest gradually as data accumulates and user count grows. Systems handling\
    \ 10 users with 10,000 records respond instantly. The same system with 100 users\
    \ and 1 million records degrades to unusable slowness due to unindexed queries,\
    \ memory exhaustion, or architectural limitations that weren't obvious during\
    \ initial deployment.\n\n## Performance Measurement and Profiling\n\nApplication\
    \ performance measurement focuses on end-user experience and system responsiveness.\
    \ Establish baselines for critical user journeys: login time, page load times\
    \ for common views (list, form, kanban), report generation duration, and transaction\
    \ processing speeds. Use browser developer tools (Chrome DevTools, Firefox Profiler)\
    \ to measure client-side metrics: DOM content loaded time, time to interactive,\
    \ first contentful paint, and JavaScript execution time. Implement Real User Monitoring\
    \ (RUM) with tools like Google Analytics, New Relic Browser, or open-source alternatives\
    \ to track actual user experience across geographic locations and device types.\
    \ Server-side metrics include: HTTP response times by endpoint, ORM query counts\
    \ per request (detect N+1 problems), cache hit rates, and session management overhead.\
    \ Set performance budgets: pages should load in <2 seconds on 3G, forms should\
    \ respond in <500ms.\n\nMeasure before optimizing to establish baseline metrics\
    \ and identify actual bottlenecks rather than assumed problems. Use Odoo's built-in\
    \ profiling through `--log-handler=odoo.sql_db:DEBUG` for database query logging\
    \ and `--dev=all` for request profiling.\n\nInstall monitoring tools that track\
    \ CPU usage, memory consumption, disk I/O, and database query patterns. Prometheus\
    \ with Grafana provides historical metrics visualization. New Relic or DataDog\
    \ offer application performance monitoring with automatic bottleneck detection.\
    \ Set up monitoring before performance problems emerge—historical data enables\
    \ trend analysis impossible with point-in-time measurements.\n\nKey performance\
    \ indicators include:\n- Average page load time (target: <2 seconds)\n- 95th percentile\
    \ response time (target: <5 seconds) \n- Database queries per request (target:\
    \ <20)\n- Memory usage per worker (target: <512MB)\n- CPU utilization (target:\
    \ <80% sustained)\n\nEstablish acceptable thresholds for your use case. Manufacturing\
    \ operations tolerate 5-second page loads if they only access the system occasionally.\
    \ E-commerce sites require sub-second response times because slow checkouts abandon\
    \ sales.\n\n## Database Query Optimization\n\nDatabase optimization focuses on\
    \ query efficiency and connection management for Odoo workloads. Identify slow\
    \ queries using Odoo's --log-db-level=debug setting combined with PostgreSQL slow\
    \ query log. Common optimization techniques: (1) Eliminate N+1 queries by using\
    \ ORM read() with field lists instead of browse() loops, prefetch related records\
    \ with .with_prefetch(), batch database operations. (2) Add strategic indexes\
    \ on foreign keys, state fields, and frequently filtered columns. Use partial\
    \ indexes for state-based queries (active records, draft documents). (3) Implement\
    \ database query result caching using Redis for expensive aggregations and reports.\
    \ Cache TTL: 5 minutes for volatile data, 1 hour for reference data. (4) Optimize\
    \ ORM operations: use search_count() instead of len(search()), use exists() for\
    \ existence checks, avoid unnecessary field reads. (5) Configure PostgreSQL for\
    \ Odoo: shared_buffers=4-8GB, effective_cache_size=12-16GB, work_mem=50MB, max_connections=200\
    \ with connection pooling. Monitor query performance weekly and maintain index\
    \ health with regular REINDEX on heavily updated tables. Expected improvement:\
    \ 30-50% reduction in database load.\n\nPostgreSQL query performance dominates\
    \ Odoo's overall speed. Slow queries block worker threads, delaying all requests\
    \ handled by that worker. A single unindexed query scanning 1 million rows stalls\
    \ operations for 10-30 seconds depending on hardware.\n\nIdentify slow queries\
    \ through PostgreSQL's pg_stat_statements extension. Enable with `CREATE EXTENSION\
    \ pg_stat_statements;` then query for slowest operations:\n\n```sql\nSELECT query,\
    \ calls, total_time, mean_time\nFROM pg_stat_statements\nORDER BY mean_time DESC\n\
    LIMIT 20;\n```\n\nCommon database performance issues:\n- **Missing indexes**:\
    \ Queries without appropriate indexes scan entire tables. Add indexes on foreign\
    \ key fields, frequently filtered fields, and sort columns.\n- **N+1 query problem**:\
    \ Looping over records and accessing related fields generates separate queries\
    \ per iteration. Use `read()` or `search_read()` with field lists to prefetch\
    \ data in single queries.\n- **Unoptimized domains**: Complex domain filters with\
    \ OR operators can't use indexes efficiently. Restructure domains to enable index\
    \ usage or create database views for common filter combinations.\n- **Dead tuples\
    \ accumulation**: PostgreSQL's MVCC creates dead tuples during updates that waste\
    \ space and slow queries. Run VACUUM ANALYZE weekly and configure autovacuum aggressively\
    \ for high-traffic tables.\n\nOptimize queries systematically:\n1. Run EXPLAIN\
    \ ANALYZE on slow queries to understand execution plans\n2. Add indexes on unindexed\
    \ columns appearing in WHERE clauses\n3. Rewrite ORM queries to use more efficient\
    \ methods (search_read vs browse)\n4. Denormalize data to avoid expensive JOIN\
    \ operations in critical queries\n\n## Server Configuration and Resource Allocation\n\
    \nApplication server tuning optimizes Odoo configuration for performance and scalability.\
    \ (1) Odoo Configuration (/etc/odoo/odoo.conf): Set db_maxconn=64 (PostgreSQL\
    \ connections per worker), workers=8 (based on CPU cores), limit_memory_hard=2684354560\
    \ (2.5GB per worker), limit_time_real=120 (request timeout). Enable proxy mode\
    \ if behind reverse proxy (proxy_mode=True). (2) Session Management: Configure\
    \ session storage in Redis instead of PostgreSQL for better performance - SESSION_REDIS=True,\
    \ session_store_timeout=86400 (24 hours). Implement session cleanup cron job to\
    \ prevent bloat. (3) Asset Management: Enable asset bundle caching with proper\
    \ ETags, configure nginx to serve static assets with 1-year cache headers, implement\
    \ CDN for global deployments. Precompile assets in production: odoo-bin --load-language=en_US\
    \ --stop-after-init. (4) Database Connection Pooling: Implement PgBouncer between\
    \ Odoo and PostgreSQL with pool_mode=transaction, default_pool_size=25, reserve_pool_size=5.\
    \ (5) Logging Configuration: Set log_level=warn for production (avoid debug/info\
    \ overhead), implement log rotation with max size 100MB, retain 30 days of logs.\
    \ Use syslog for centralized logging. Configure log_db=False to avoid logging\
    \ database queries in production. Expected improvement: 20-35% reduction in response\
    \ times under load.\n\nOdoo's multiprocess architecture spawns worker processes\
    \ handling concurrent requests. Worker count follows formula: `(CPU_cores × 2)\
    \ + 1` for balanced concurrency without oversubscription. Fewer workers creates\
    \ queuing delays. Excessive workers exhaust memory causing swap thrashing that\
    \ grinds performance to a halt.\n\nMemory per worker depends on data complexity\
    \ and loaded modules. Typical installations require 256-512MB per worker. Monitor\
    \ actual memory usage through `ps aux | grep odoo` and adjust worker limits accordingly:\n\
    \n```ini\n[options]\nworkers = 9  # For 4-core CPU\nmax_cron_threads = 2\nlimit_memory_hard\
    \ = 2684354560  # 2.5GB per worker\nlimit_memory_soft = 2147483648  # 2GB soft\
    \ limit\nlimit_time_cpu = 600  # 10 minutes CPU time\nlimit_time_real = 1200 \
    \ # 20 minutes real time\n```\n\nThe soft limit triggers worker recycling when\
    \ exceeded—Odoo spawns fresh worker and terminates the old one after request completion.\
    \ Hard limit kills worker immediately preventing runaway processes from consuming\
    \ all system memory.\n\nPostgreSQL tuning parameters significantly impact query\
    \ performance:\n\n```ini\nshared_buffers = 4GB  # 25% of system RAM\neffective_cache_size\
    \ = 12GB  # 50% of system RAM  \nwork_mem = 64MB  # Memory per query operation\n\
    maintenance_work_mem = 1GB  # Memory for VACUUM/REINDEX\nrandom_page_cost = 1.1\
    \  # SSD-optimized (4.0 for HDD)\n```\n\nRestart PostgreSQL after configuration\
    \ changes. Monitor impact through pg_stat_database views comparing query times\
    \ before and after tuning.\n\n## Asset and Static Content Optimization\n\nAsset\
    \ optimization reduces page load times through compression, caching, and delivery\
    \ optimization. (1) JavaScript/CSS Minification: Enable Odoo asset bundling in\
    \ production mode, combine multiple JS/CSS files into single bundles to reduce\
    \ HTTP requests. Use Odoo asset management to version bundles with hash-based\
    \ cache busting. (2) Image Optimization: Compress images using ImageMagick/Pillow\
    \ before upload - JPEG quality 85%, PNG with pngquant compression. Implement responsive\
    \ images with multiple resolutions using picture elements. Convert large images\
    \ to WebP format for 25-35% size reduction with browser fallbacks. Lazy load images\
    \ below the fold using lazy loading attribute. (3) Static Asset Caching: Configure\
    \ nginx to serve static assets with aggressive caching headers (Cache-Control:\
    \ public, max-age=31536000) for JS/CSS/images with version hashes. Enable gzip\
    \ compression for text assets (gzip_types application/javascript text/css). Implement\
    \ Brotli compression for even better ratios (brotli_comp_level=6). (4) CDN Integration:\
    \ Deploy static assets to CloudFlare, AWS CloudFront, or Fastly CDN for geographic\
    \ distribution. Configure edge caching with 1-hour TTL for dynamic content, 1-year\
    \ for static. (5) Font Optimization: Self-host web fonts instead of Google Fonts\
    \ API, subset fonts to include only used characters (reduces size by 70-90%),\
    \ use font-display:swap to prevent render blocking. Preload critical fonts in\
    \ HTML head element. Expected improvement: 50-70% reduction in page load time,\
    \ 40-60% reduction in bandwidth usage.\n\nOdoo serves JavaScript, CSS, and images\
    \ through application workers competing with business logic for worker availability.\
    \ During peak usage, static asset requests saturate workers leaving no capacity\
    \ for actual business operations.\n\nConfigure NGINX reverse proxy to serve static\
    \ content directly without invoking Odoo workers:\n\n```nginx\nlocation /web/static\
    \ {\n    proxy_cache_bypass $http_pragma $http_authorization;\n    proxy_cache\
    \ static_cache;\n    proxy_cache_valid 200 60m;\n    proxy_pass http://odoo_backend;\n\
    }\n\nlocation ~* \\.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {\n    expires\
    \ 30d;\n    add_header Cache-Control \"public, immutable\";\n}\n```\n\nEnable\
    \ Gzip compression for text assets reducing transfer size by 70-80%:\n\n```nginx\n\
    gzip on;\ngzip_types text/css application/javascript application/json image/svg+xml;\n\
    gzip_min_length 1000;\n```\n\nImplement browser caching through Cache-Control\
    \ headers. Static assets (images, fonts) cache for 30 days. Dynamic content (HTML,\
    \ API responses) caches for 5 minutes with revalidation.\n\nUse CDN for global\
    \ deployments to serve static content from edge locations near users. CloudFlare,\
    \ Fastly, or AWS CloudFront cache assets globally reducing latency for international\
    \ users.\n\n## Module and Code Optimization\n\nModule optimization focuses on\
    \ custom code efficiency and reducing computational overhead. (1) ORM Optimization:\
    \ Replace search() + browse() loops with read() for bulk operations - reduces\
    \ database queries by 80-95%. Use search_read() when only reading fields. Implement\
    \ with_prefetch() for related records to prevent N+1 queries. Avoid unnecessary\
    \ field reads by specifying field lists in read(['name', 'state']). (2) Computed\
    \ Fields: Use @api.depends() decorator correctly to limit recomputation scope,\
    \ implement store=True for frequently accessed computed fields if calculation\
    \ is expensive, use inverse methods for writable computed fields. Cache expensive\
    \ computations using @tools.ormcache decorator with cache invalidation on relevant\
    \ record changes. (3) Batch Processing: Process records in batches of 500-1000\
    \ using custom iterators, disable mail notification during bulk operations with\
    \ context flag ({'mail_create_nolog': True}), commit transactions periodically\
    \ in long-running imports. Use cr.commit() judiciously in batch operations. (4)\
    \ Server Actions: Convert button click actions to scheduled actions for heavy\
    \ processing (report generation, mass updates), implement asynchronous processing\
    \ using queue_job module for user-initiated batch operations. (5) Code Profiling:\
    \ Use cProfile to identify bottlenecks (python -m cProfile -o output.prof odoo-bin),\
    \ analyze with snakeviz for visualization. Use line_profiler for function-level\
    \ profiling. Optimize hot paths identified in profiling - typical gains: 60-80%\
    \ reduction in execution time for critical functions. (6) Remove Debug Code: Disable\
    \ development mode in production, remove unnecessary logging statements, disable\
    \ auto-reload (--dev=reload). Expected improvement: 40-70% reduction in custom\
    \ module execution time.\n\nPoorly written custom modules create performance problems\
    \ invisible during development with small datasets. Inefficient code patterns\
    \ compound at scale—operations taking milliseconds with 100 records take minutes\
    \ with 100,000 records.\n\nCommon module performance issues:\n\n**Inefficient\
    \ ORM usage**: Calling `write()` inside loops updates records one-by-one generating\
    \ separate SQL updates. Batch operations with `write()` on recordsets update all\
    \ records in single queries:\n\n```python\n# Bad: N database writes\nfor record\
    \ in self.line_ids:\n    record.write({'state': 'done'})\n\n# Good: 1 database\
    \ write\nself.line_ids.write({'state': 'done'})\n```\n\n**Unnecessary database\
    \ access**: Accessing record fields inside loops triggers SQL queries per iteration.\
    \ Prefetch data outside loops using `read()` or mapped():\n\n```python\n# Bad:\
    \ N+1 queries\nfor order in orders:\n    print(order.partner_id.name)  # Database\
    \ query per iteration\n\n# Good: 2 queries total\npartners = orders.mapped('partner_id')\n\
    for order in orders:\n    print(order.partner_id.name)  # Uses prefetched data\n\
    ```\n\n**Unoptimized searches**: Searching entire table then filtering in Python\
    \ wastes database resources. Apply filters in domain expressions to leverage database\
    \ indexes:\n\n```python\n# Bad: Fetches all records, filters in Python\nall_orders\
    \ = self.env['sale.order'].search([])\nlate_orders = [o for o in all_orders if\
    \ o.state == 'late']\n\n# Good: Database filters efficiently\nlate_orders = self.env['sale.order'].search([('state',\
    \ '=', 'late')])\n```\n\n**Heavy computed fields**: Computed fields recalculate\
    \ whenever dependencies change. Expensive computations (API calls, complex calculations)\
    \ trigger on every record access. Cache computed values or replace with stored\
    \ fields for expensive operations.\n\n## Caching Strategies\n\nCaching strategy\
    \ implementation requires multi-layer approach for maximum performance gains.\
    \ (1) Application-Level Caching (Redis): Install Redis server, configure Odoo\
    \ session storage to use Redis instead of PostgreSQL database (reduces DB load\
    \ by 40-60%). Cache expensive method results using @tools.ormcache decorator with\
    \ custom cache keys - example: @tools.ormcache('product_id', 'pricelist_id') def\
    \ get_product_price(). Implement cache invalidation using ormcache_context on\
    \ fields that affect cached values. Set Redis maxmemory-policy=allkeys-lru for\
    \ automatic eviction. (2) Database Query Caching: Cache complex report queries\
    \ in Redis with 5-15 minute TTL depending on data volatility. Implement invalidation\
    \ triggers on relevant table updates. Use Redis HSET for structured cache (product\
    \ prices, tax calculations) and GET/SET for simple values. Cache aggregation queries\
    \ (dashboard statistics, KPI metrics) with 1-hour TTL. (3) HTTP Caching: Configure\
    \ nginx proxy caching for semi-static content (public pages, product catalogs)\
    \ with proxy_cache_valid 200 5m. Implement cache key based on URL + user authentication\
    \ state. Set X-Accel-Expires header in Odoo controllers for per-response cache\
    \ control. Use nginx fastcgi_cache or proxy_cache with 10GB cache zone. (4) Browser\
    \ Caching: Set appropriate Cache-Control headers - static assets: max-age=31536000\
    \ (1 year), API responses: max-age=300 (5 minutes), dynamic pages: no-cache with\
    \ ETags for validation. Implement service workers for offline-capable progressive\
    \ web app functionality. (5) Object Caching: Enable Python function result caching\
    \ using functools.lru_cache for pure functions, implement model-level caching\
    \ for reference data (countries, currencies, units of measure) that rarely changes.\
    \ Monitor cache hit rates using Redis INFO stats, target >80% hit rate for optimal\
    \ performance. Expected improvement: 60-80% reduction in page load time for cached\
    \ content, 50% reduction in database load.\n\nImplement caching at multiple levels\
    \ to avoid redundant calculations:\n\n**Application-level caching**: Use Python's\
    \ lru_cache decorator for expensive pure functions:\n\n```python\nfrom functools\
    \ import lru_cache\n\n@lru_cache(maxsize=1000)\ndef calculate_discount(price,\
    \ tier, region):\n    # Expensive calculation cached for repeated calls\n    return\
    \ complex_discount_logic(price, tier, region)\n```\n\n**Database query caching**:\
    \ PostgreSQL caches query results automatically but benefits from consistent query\
    \ patterns. Use parameterized queries rather than string concatenation for better\
    \ cache hit rates.\n\n**Redis caching**: Deploy Redis for distributed caching\
    \ across multiple Odoo workers. Cache expensive API responses, computed aggregates,\
    \ and frequently accessed configuration:\n\n```python\nimport redis\nr = redis.Redis(host='localhost',\
    \ port=6379, db=0)\n\n# Cache expensive calculation\nkey = f\"price_calculation_{product_id}_{pricelist_id}\"\
    \ncached = r.get(key)\nif cached:\n    return float(cached)\nelse:\n    result\
    \ = expensive_price_calculation()\n    r.setex(key, 300, result)  # Cache for\
    \ 5 minutes\n    return result\n```\n\n**HTTP caching**: Configure Odoo to send\
    \ proper cache headers for API endpoints serving relatively static data. Enable\
    \ client-side caching reducing server load for repeated requests.\n\n## Monitoring\
    \ and Continuous Optimization\n\nComprehensive monitoring strategy enables proactive\
    \ performance management and issue detection. (1) System Monitoring: Deploy Prometheus\
    \ with node_exporter for OS metrics collection (CPU, memory, disk, network) with\
    \ 15-second scrape intervals. Configure Grafana dashboards for visualization with\
    \ alert rules: CPU >85% for 5 minutes, memory >90%, disk >80%, filesystem inodes\
    \ >90%. Set up multi-level alerts: warning (Slack notification), critical (PagerDuty\
    \ incident). Monitor system logs using Loki or ELK stack for error pattern detection.\
    \ (2) Application Monitoring: Implement Odoo-specific monitoring using custom\
    \ Prometheus exporters tracking: active user sessions, database query counts per\
    \ endpoint, ORM operation statistics, worker process metrics (memory per worker,\
    \ request queue depth), cron job execution times. Set up APM (Application Performance\
    \ Monitoring) using New Relic, DataDog, or open-source alternatives (Elastic APM)\
    \ for request tracing and error tracking. Alert on: response time >2 seconds for\
    \ critical endpoints, error rate >1%, worker saturation >80%. (3) Database Monitoring:\
    \ Monitor PostgreSQL using pg_stat_statements for query performance tracking,\
    \ enable auto_explain for slow queries (auto_explain.log_min_duration=1000), track\
    \ connection pool usage with PgBouncer stats. Set up pgBadger for weekly performance\
    \ reports, monitor replication lag if using streaming replication. Alert on: slow\
    \ queries >5 seconds, database connections >80% of max_connections, replication\
    \ lag >10 seconds, disk space <20% free. (4) Business Metrics: Track KPIs using\
    \ custom Odoo scheduled actions: orders per hour, failed payment transactions,\
    \ inventory stock-outs, unprocessed emails. Create executive dashboards in Grafana\
    \ showing business health alongside technical metrics. (5) Log Analysis: Centralize\
    \ logs using Graylog or ELK stack, implement structured logging with JSON format\
    \ for machine parsing. Create alerts for specific error patterns, track error\
    \ frequency trends over time. Implement log retention policy: 7 days hot storage,\
    \ 90 days warm storage, 1 year cold storage for compliance. Expected outcome:\
    \ Detect and resolve 90% of performance issues before user impact, reduce mean\
    \ time to detection (MTTD) from hours to minutes.\n\nPerformance degrades gradually\
    \ as data accumulates and usage patterns evolve. Establish continuous monitoring\
    \ detecting degradation before users complain.\n\nTrack key metrics over time:\n\
    - Average response time trends (increasing suggests degradation)\n- Slowest database\
    \ queries (candidates for optimization)\n- Memory usage patterns (growing suggests\
    \ memory leaks)\n- Error rates (increasing indicates capacity problems)\n\nSet\
    \ up automated alerting:\n- Response time exceeds 5 seconds for 5 consecutive\
    \ minutes\n- Database connections approach connection pool limits\n- Memory usage\
    \ exceeds 80% for sustained periods\n- Error rates spike above baseline by 50%\n\
    \nSchedule quarterly performance reviews analyzing trends and identifying optimization\
    \ opportunities. Database growth, new modules, and evolving usage patterns change\
    \ performance characteristics requiring ongoing tuning rather than one-time optimization.\n"
  conclusion: 'Performance optimization delivers business value through improved user
    productivity that compound daily across your workforce. Report generation completing
    in seconds rather than minutes eliminates wait time that disrupts workflow concentration.
    Search operations returning results immediately rather than timing out enables
    efficient customer service. Month-end financial closes completing overnight rather
    than requiring manual intervention preserves accounting team capacity for analysis
    rather than data processing. These productivity improvements accumulate to justify
    optimization investment through eliminated wasted time.


    Gather user feedback systematically after optimization deployment to validate
    that technical improvements translated to perceived user experience enhancement.
    Users sometimes don''t notice gradual performance degradation that occurred over
    months because they adapted workflow to accommodate system limitations—they might
    not immediately recognize improvement without prompting. Conduct brief surveys
    asking users to compare current system responsiveness to pre-optimization performance,
    identifying workflows still exhibiting problems requiring additional tuning focus.


    Calculate productivity impact quantitatively by measuring time savings from performance
    improvement applied across user population. If report generation time decreased
    from two minutes to thirty seconds across twenty users generating reports five
    times daily, that represents cumulative time savings of twenty-five hours weekly—justifying
    substantial optimization investment through eliminated waste. Quantified productivity
    improvements demonstrate technology investment value to business stakeholders
    who evaluate IT spending through operational impact lens rather than technical
    sophistication.



    New to self-hosting Odoo? Join 2,400+ business owners getting our weekly implementation
    guides delivered straight to your inbox. Each guide covers one specific challenge
    with tested solutions and ready-to-use configurations.'
  extended_content: ''
conversion_assets:
- component_type: callout-box
  placement_hint: mid_guide
  generated_copy:
    headline: CloudWatch Agent and Alarms
    body: Health monitoring and performance tracking tools
    cta_text: CloudWatch Agent and Alarms
    cta_link: /downloads/cloudwatch-agent-and-alarms/
    cta_context: Priority 2.5 link from intelligent linking system
- component_type: callout-box
  placement_hint: post_technical
  generated_copy:
    headline: Real-Time Breach Monitoring
    body: Health monitoring and performance tracking tools
    cta_text: Real-Time Breach Monitoring
    cta_link: /downloads/real-time-breach-monitoring/
    cta_context: Priority 2.5 link from intelligent linking system
intelligent_links:
- link_url: /odoo-implementation-guide/
  anchor_text: Complete Implementation Guide
  context: Master implementation planning to avoid $250K+ failures
  link_type: implementation_guide
  priority: 5.5
- link_url: /guides/odoo-performance-metrics/
  anchor_text: 'Optimize Application Performance: Improve Performance by 50%'
  context: Set up performance monitoring
  link_type: monitoring_setup
  priority: 3.5
- link_url: /guides/odoo-auto-scaling/
  anchor_text: 'Optimize Application Performance: Improve Performance by 50%'
  context: Scale your infrastructure
  link_type: scaling_guide
  priority: 6.0
visualizations:
- chart_type: mermaid
  placement_hint: after_troubleshooting
  data_context: performance workflow visualization (semantic variant)
  mermaid_chart_syntax: "flowchart LR\n    Start([Slow Queries]) --> Identify[Identify\
    \ Slow Queries]\n    Identify --> Analyze[Analyze Execution Plans]\n    Analyze\
    \ --> Index[Create Missing Indexes]\n    Index --> Rewrite[Rewrite Inefficient\
    \ Queries]\n    Rewrite --> Stats[Update Database Statistics]\n    Stats --> Test[Performance\
    \ Testing]\n    Test --> End([Queries Optimized])\n\n    classDef diagnosis fill:#ff9800,stroke:#f57c00,stroke-width:2px,color:#fff\n\
    \    classDef optimization fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff\n\
    \    classDef success fill:#d4edda,stroke:#28a745,stroke-width:2px\n\n    class\
    \ Identify,Analyze diagnosis\n    class Index,Rewrite,Stats,Test optimization\n\
    \    class Start,End success\n"
  variant_id: performance_chart_001
- chart_type: mermaid
  placement_hint: after_prerequisites
  data_context: 'Phase 1: Performance Profiling'
  mermaid_chart_syntax: "flowchart TB\n    Start([Baseline]) --> Enable[Enable Query\
    \ Logging]\n    Enable --> Capture[Capture Performance Metrics]\n    Capture -->\
    \ Identify[Identify Bottlenecks]\n    Identify --> Prioritize[Prioritize by Impact]\n\
    \    Prioritize --> Document[Document Findings]\n    Document --> End([Profile\
    \ Complete])\n\n    classDef profiling fill:#2196f3,stroke:#1976d2,stroke-width:2px,color:#fff\n\
    \    classDef analysis fill:#ff9800,stroke:#f57c00,stroke-width:2px,color:#fff\n\
    \    classDef success fill:#d4edda,stroke:#28a745,stroke-width:2px\n\n    class\
    \ Enable,Capture profiling\n    class Identify,Prioritize,Document analysis\n\
    \    class Start,End success\n"
  variant_id: performance_chart_001_profiling
- chart_type: mermaid
  placement_hint: after_steps
  data_context: 'Phase 2: Index Strategy'
  mermaid_chart_syntax: "flowchart LR\n    Start([Index Analysis]) --> Missing[Find\
    \ Missing Indexes]\n    Missing --> Duplicate[Remove Duplicate Indexes]\n    Duplicate\
    \ --> Composite[Create Composite Indexes]\n    Composite --> Partial[Add Partial\
    \ Indexes]\n    Partial --> Validate[Validate Index Usage]\n    Validate --> End([Indexes\
    \ Optimized])\n\n    classDef index fill:#4caf50,stroke:#388e3c,stroke-width:2px,color:#fff\n\
    \    classDef validation fill:#2196f3,stroke:#1976d2,stroke-width:2px,color:#fff\n\
    \    classDef success fill:#d4edda,stroke:#28a745,stroke-width:2px\n\n    class\
    \ Missing,Duplicate,Composite,Partial index\n    class Validate validation\n \
    \   class Start,End success\n"
  variant_id: performance_chart_001_indexes
- chart_type: mermaid
  placement_hint: after_conclusion
  data_context: learning path and knowledge graph
  mermaid_chart_syntax: "flowchart TB\n\n    Current[\"⬤ Optimize Application Performance:\
    \ Improve Performance by 50%\"]\n\n    %% Next Steps - Learning Progression\n\
    \    Current --> Next0(\"Optimize Application Performance: Improve Performance\
    \ by 50%\")\n\n    %% Support Resources - Training & Tools\n    Current -.-> Support0[\"\
    Optimize Application Performance: Improve Performance by 50%\"]\n\n    %% Professional\
    \ Styling\n    classDef current fill:#ffc107,stroke:#ff9800,stroke-width:3px,color:#000\n\
    \    classDef prereq fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000\n\
    \    classDef next fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#000\n \
    \   classDef related fill:#f5f5f5,stroke:#616161,stroke-width:1px,color:#000\n\
    \    classDef trouble fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000\n\
    \    classDef support fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n\
    \n    class Current current\n    class Next0 next\n    class Support0 support"
